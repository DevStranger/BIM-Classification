# Importy
import pandas as pd
import json
from sentence_transformers import SentenceTransformer, util

# Wczytanie danych IFC
ifc_df = pd.read_csv("data/ifc_sample.csv")

# Wczytanie klas CCI
with open("data/cci_sample.json", "r", encoding="utf-8") as f:
    cci_data = json.load(f)

cci_df = pd.DataFrame(cci_data)

# Załaduj model embeddingowy
model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")

# Wygeneruj embeddingi
ifc_embeddings = model.encode(ifc_df["Text"].tolist(), convert_to_tensor=True)
cci_embeddings = model.encode(cci_df["full_text"].tolist(), convert_to_tensor=True)

# Dla każdego opisu IFC znajdź najbardziej podobną klasę CCI
results = []
for i, ifc_emb in enumerate(ifc_embeddings):
    # Liczymy podobieństwa do wszystkich klas
    similarities = util.cos_sim(ifc_emb, cci_embeddings)[0]
    best_idx = similarities.argmax().item()
    best_score = similarities[best_idx].item()
    
    # Dodajemy do wyników
    results.append({
        "GlobalId": ifc_df.loc[i, "GlobalId"],
        "IFC_Description": ifc_df.loc[i, "Text"],
        "Predicted_CCI_Code": cci_df.loc[best_idx, "code"],
        "Predicted_CCI_Name": cci_df.loc[best_idx, "name"],
        "Similarity": round(best_score, 4)
    })

# Tworzymy DataFrame z wynikami
results_df = pd.DataFrame(results)
results_df.sort_values("Similarity", ascending=False, inplace=True)
results_df.reset_index(drop=True, inplace=True)

# Podgląd
results_df.head(10)

